% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
%
\title{Survey em IA e Segurança}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Davi Iury \and
Esther Martins \and
Lucas Pinheiro \and 
Rafael Porto \and 
Théo Araújo}
%
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Universidade Federal do Ceará}
%
\titlerunning{Survey em IA e Segurança}
\authorrunning{D. Iury et al.}
\begin{document}
\maketitle
%
\begin{abstract}
Nós resume as coisas aqui.
\keywords{IA  \and Segurança \and  Machine Learning.}
\end{abstract}
\section{Introdução}
IA é muito popular. 
Porém, precisamos de muitos dados para treinar modelos.
Como podemos arranjar esses dados?
Mais especificamente,
como podemos arrumar esses dados de forma que não infrijamos leis de privacidade de dados?
Como privacidade de dados vem se tornando um conceito cada vez mais em voga,
Novas formas de treinar modelos e obter dados vem surgindo.
Nesta survey, falaremos de: \newline
Federated learning (analisar os dados locamente e mandar os resultados de volta 
de forma criptografada) \newline
Differential privacy (é uma técnica que visa proteger a privacidade dos usuários
por meio da adição de ruído nos dados sendo analisados) \newline
Machine Unlearning (esquecer dados de usuários que foram usados para treinar modelos de 
forma que isso não prejudique o aprendizado do algoritmo).
\subsection{Contextualização}
Deixei aqui para ser o template inicial. 
Quando forem escrever,
É legal dar enter a cada oração
Para que fique dividido direito e fique fácil de ler.
\section{Caracterização Ferramental}
\subsection{Machine unlearning}
woow
\subsection{Differential privacy}
woow
\subsection{Federated learning}
\textbf{Contexto.}
É comum que algoritmos clássicos de aprendizado de máquina
mantenham centralizados os dados a serem
usados para treinamento. Isso se deve ao fato de que, frequentemente, os dados 
encontram-se dispersos em \"{}ilhas de dados\"{}\footnote{to-do referencia.}, então,
é necessário que seja feito um trabalho de captação e agrupamento em um servidor para que o uso em treinamento seja possível. 
No entanto, caso não seja feita de forma adequada, 
essa centralização facilita o vazamento de dados sensíveis.
Em vista dessa situação, 
diversas regulações vem sendo impostas com relação à captação e ao uso de dados para treinamento de modelos,
tornando o uso de técnicas de aprendizado de máquina centralizado de difícil implementação prática. 
Nesse contexto, a aplicação do federated learning possibilita com que o treinamento seja feito de forma local, 
não-centralizada, de forma que os dados de um usuário específico mantém-se somente no seu dispositivo local.  
\newline\textbf{Definindo.}
In the practical application scenario [8], it is assumed that
N users \{{}U1, $\cdots$, Un\}{} own their own database {D1, $\cdots$, Dn}, and
each of them cannot directly access to other people's data to
expand their own data. As shown in Fig. 1, federated learning is to
learn a model by collecting training information from distributed
devices. It contains three basic steps [10]: (1) Server sends the
initial model to each device. (2) The device Ui does not need to
share its own source data, but can federally train its own model
Wi with the local data Di. (3) Server aggregates the collected local
models \{{}W1, $\cdots$, Wn\}{} to the global model W\'{}, and then update 
global model to replace each user's local model. With the rapid
development of federated learning, the efficiency and accuracy
of federated training models are getting closer and closer to
centralized training models [11]. It is playing an important role
in many areas that need to take into account privacy. 
\newline\textbf{Tipos.} 
1. Com relação à partição dos dados.
2. Com relação à mecanismos de privacidade
3. Com relação ao modelo de ML aplicado 
4. Com relação ao método de solucionar heterogênidade. 
\newline\textbf{Aplicações práticas.}

\section{Desafios}

% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
% \begin{thebibliography}{8}
% \end{thebibliography}
\end{document}
