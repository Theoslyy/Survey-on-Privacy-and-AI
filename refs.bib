@article{zhang2021survey,
title = {A survey on federated learning},
journal = {Knowledge-Based Systems},
volume = {216},
pages = {106775},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.106775},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121000381},
author = {Chen Zhang and Yu Xie and Hang Bai and Bin Yu and Weihong Li and Yuan Gao},
keywords = {Federated learning, Privacy protection, Machine learning},
abstract = {Federated learning is a set-up in which multiple clients collaborate to solve machine learning problems, which is under the coordination of a central aggregator. This setting also allows the training data decentralized to ensure the data privacy of each device. Federated learning adheres to two major ideas: local computing and model transmission, which reduces some systematic privacy risks and costs brought by traditional centralized machine learning methods. The original data of the client is stored locally and cannot be exchanged or migrated. With the application of federated learning, each device uses local data for local training, then uploads the model to the server for aggregation, and finally the server sends the model update to the participants to achieve the learning goal. To provide a comprehensive survey and facilitate the potential research of this area, we systematically introduce the existing works of federated learning from five aspects: data partitioning, privacy mechanism, machine learning model, communication architecture and systems heterogeneity. Then, we sort out the current challenges and future research directions of federated learning. Finally, we summarize the characteristics of existing federated learning, and analyze the current practical application of federated learning.}
}

@misc{mcmahan2017communication,
      title={Communication-Efficient Learning of Deep Networks from Decentralized Data}, 
      author={H. Brendan McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Agüera y Arcas},
      year={2023},
      eprint={1602.05629},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1602.05629}, 
}

@inbook{yang2020,
      author={Yang, Qiang and Liu, Yang and Cheng, Yong and Kang, Yan and Chen, Tianjian and Yu, Han},
      title={Federated Transfer Learning},
      bookTitle={Federated Learning},
      year={2020},
      publisher={Springer International Publishing},
      address={Cham},
      pages={83--93},
      abstract={We have discussed horizontal federated learning (HFL) and vertical federated learning (VFL) in Chapters 4 and 5, respectively. HFL requires all participating parties share the same feature space while VFL require parties share the same sample space. In practice, however, we often face situations in which there are not enough shared features or samples among the participating parties. In those cases, one can still build a federated learning model combined with transfer learning that transfers knowledge among the parties to achieve better performance. We refer to the combination of federated learning and transfer learning as Federated Transfer Learning (FTL). In this chapter, we provide a formal definition of FTL and discuss the differences between FTL and traditional transfer learning. We then introduce a secure FTL framework proposed in Liu et al. [2019], and conclude this chapter with a summary of the challenges and open issues.},
      isbn={978-3-031-01585-4},
      doi={10.1007/978-3-031-01585-4_6},
}

@inproceedings{bonawitz2017practical,
author = {Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H. Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
title = {Practical Secure Aggregation for Privacy-Preserving Machine Learning},
year = {2017},
isbn = {9781450349468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133956.3133982},
doi = {10.1145/3133956.3133982},
abstract = {We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and active adversary settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers $1.73 x communication expansion for 210 users and 220-dimensional vectors, and 1.98 x expansion for 214 users and 224-dimensional vectors over sending data in the clear.},
booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1175-1191},
numpages = {17},
keywords = {federated learning, machine learning, privacy-preserving protocols, secure aggregation},
location = {Dallas, Texas, USA},
series = {CCS '17}
}

@misc{mcmahan2018learning,
      title={Learning Differentially Private Recurrent Language Models}, 
      author={H. Brendan McMahan and Daniel Ramage and Kunal Talwar and Li Zhang},
      year={2018},
      eprint={1710.06963},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1710.06963}, 
}

@misc{hardy2017private,
      title={Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption}, 
      author={Stephen Hardy and Wilko Henecka and Hamish Ivey-Law and Richard Nock and Giorgio Patrini and Guillaume Smith and Brian Thorne},
      year={2017},
      eprint={1711.10677},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.10677}, 
}
@misc{cheng2021secureboost,
      title={SecureBoost: A Lossless Federated Learning Framework}, 
      author={Kewei Cheng and Tao Fan and Yilun Jin and Yang Liu and Tianjian Chen and Dimitrios Papadopoulos and Qiang Yang},
      year={2021},
      eprint={1901.08755},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1901.08755}, 
}

@inproceedings{nikolaenko2013privacy,
author = {Nikolaenko, Valeria and Weinsberg, Udi and Ioannidis, Stratis and Joye, Marc and Boneh, Dan and Taft, Nina},
year = {2013},
month = {05},
pages = {334-348},
booktitle= {Security and Privacy},
title = {Privacy-Preserving Ridge Regression on Hundreds of Millions of Records},
isbn = {978-1-4673-6166-8},
journal = {IEEE Symposium on Security and Privacy},
doi = {10.1109/SP.2013.30}
}

@misc{bonawitz2019towards,
      title={Towards Federated Learning at Scale: System Design}, 
      author={Keith Bonawitz and Hubert Eichner and Wolfgang Grieskamp and Dzmitry Huba and Alex Ingerman and Vladimir Ivanov and Chloe Kiddon and Jakub Konečný and Stefano Mazzocchi and H. Brendan McMahan and Timon Van Overveldt and David Petrou and Daniel Ramage and Jason Roselander},
      year={2019},
      eprint={1902.01046},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1902.01046}, 
}

@misc{fan2022fault,
      title={Fault-Tolerant Federated Reinforcement Learning with Theoretical Guarantee}, 
      author={Flint Xiaofeng Fan and Yining Ma and Zhongxiang Dai and Wei Jing and Cheston Tan and Bryan Kian Hsiang Low},
      year={2022},
      eprint={2110.14074},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14074}, 
}

@misc{liang2020think,
      title={Think Locally, Act Globally: Federated Learning with Local and Global Representations}, 
      author={Paul Pu Liang and Terrance Liu and Liu Ziyin and Nicholas B. Allen and Randy P. Auerbach and David Brent and Ruslan Salakhutdinov and Louis-Philippe Morency},
      year={2020},
      eprint={2001.01523},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2001.01523}, 
}

@misc{nadas2025,
      title={Synthetic Data Generation Using Large Language Models: Advances in Text and Code},
      volume={13},
      ISSN={2169-3536},
      url={http://dx.doi.org/10.1109/ACCESS.2025.3589503},
      DOI={10.1109/access.2025.3589503},
      journal={IEEE Access},
      publisher={Institute of Electrical and Electronics Engineers (IEEE)},
      author={Nadǎş, Mihai and Dioşan, Laura and Tomescu, Andreea},
      year={2025},
      pages={134615–134633} 
}

@misc{goyal2024,
      AUTHOR = {Goyal, Mandeep and Mahmoud, Qusay H.},
      TITLE = {A Systematic Review of Synthetic Data Generation Techniques Using Generative AI},
      JOURNAL = {Electronics},
      VOLUME = {13},
      YEAR = {2024},
      NUMBER = {17},
      ARTICLE-NUMBER = {3509},
      URL = {https://www.mdpi.com/2079-9292/13/17/3509},
      ISSN = {2079-9292},
      ABSTRACT = {Synthetic data are increasingly being recognized for their potential to address serious real-world challenges in various domains. They provide innovative solutions to combat the data scarcity, privacy concerns, and algorithmic biases commonly used in machine learning applications. Synthetic data preserve all underlying patterns and behaviors of the original dataset while altering the actual content. The methods proposed in the literature to generate synthetic data vary from large language models (LLMs), which are pre-trained on gigantic datasets, to generative adversarial networks (GANs) and variational autoencoders (VAEs). This study provides a systematic review of the various techniques proposed in the literature that can be used to generate synthetic data to identify their limitations and suggest potential future research areas. The findings indicate that while these technologies generate synthetic data of specific data types, they still have some drawbacks, such as computational requirements, training stability, and privacy-preserving measures which limit their real-world usability. Addressing these issues will facilitate the broader adoption of synthetic data generation techniques across various disciplines, thereby advancing machine learning and data-driven solutions.},
      DOI = {10.3390/electronics13173509}
}
@misc{lu2023,
      title={Machine Learning for Synthetic Data Generation: A Review}, 
      author={Yingzhou Lu and Lulu Chen and Yuanyuan Zhang and Minjie Shen and Huazheng Wang and Xiao Wang and Capucine van Rechem and Tianfan Fu and Wenqi Wei},
      year={2025},
      eprint={2302.04062},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2302.04062} 
}

@article{DP01,
      title = {Differential privacy in deep learning: Privacy and beyond},
      journal = {Future Generation Computer Systems},
      volume = {148},
      pages = {408-424},
      year = {2023},
      issn = {0167-739X},
      doi = {https://doi.org/10.1016/j.future.2023.06.010},
      url = {https://www.sciencedirect.com/science/article/pii/S0167739X23002315},
      author = {Yanling Wang and Qian Wang and Lingchen Zhao and Cong Wang},
}
@article{DP02,
      title = {A review of applications in federated learning},
      journal = {Computers and Industrial Engineering},
      volume = {149},
      pages = {106854},
      year = {2020},
      issn = {0360-8352},
      doi = {https://doi.org/10.1016/j.cie.2020.106854},
      url = {https://www.sciencedirect.com/science/article/pii/S0360835220305532},
      author = {Li Li and Yuxi Fan and Mike Tse and Kuo-Yi Lin},
      keywords = {Federated learning, Literature review, Citation analysis, Research front},
}
@article{DP03,
      author = {Dwork, Cynthia and Roth, Aaron},
      title = {The Algorithmic Foundations of Differential Privacy},
      year = {2014},
      issue_date = {Aug 2014},
      publisher = {Now Publishers Inc.},
      address = {Hanover, MA, USA},
      volume = {9},
      number = {3-4},
      issn = {1551-305X},
      url = {https://doi.org/10.1561/0400000042},
      doi = {10.1561/0400000042},
      abstract = {The problem of privacy-preserving data analysis has a long history spanning multiple disciplines. As electronic data about individuals becomes increasingly detailed, and as technology enables ever more powerful collection and curation of these data, the need increases for a robust, meaningful, and mathematically rigorous definition of privacy, together with a computationally rich class of algorithms that satisfy this definition. Differential Privacy is such a definition.After motivating and discussing the meaning of differential privacy, the preponderance of this monograph is devoted to fundamental techniques for achieving differential privacy, and application of these techniques in creative combinations, using the query-release problem as an ongoing example. A key point is that, by rethinking the computational goal, one can often obtain far better results than would be achieved by methodically replacing each step of a non-private computation with a differentially private implementation. Despite some astonishingly powerful computational results, there are still fundamental limitations — not just on what can be achieved with differential privacy but on what can be achieved with any method that protects against a complete breakdown in privacy. Virtually all the algorithms discussed herein maintain differential privacy against adversaries of arbitrary computational power. Certain algorithms are computationally intensive, others are efficient. Computational complexity for the adversary and the algorithm are both discussed.We then turn from fundamentals to applications other than queryrelease, discussing differentially private methods for mechanism design and machine learning. The vast majority of the literature on differentially private algorithms considers a single, static, database that is subject to many analyses. Differential privacy in other models, including distributed databases and computations on data streams is discussed.Finally, we note that this work is meant as a thorough introduction to the problems and techniques of differential privacy, but is not intended to be an exhaustive survey — there is by now a vast amount of work in differential privacy, and we can cover only a small portion of it.},
      journal = {Found. Trends Theor. Comput. Sci.},
      pages = {211–407},
      numpages = {197}
}
@misc{DP04,
      title={Concentrated Differential Privacy}, 
      author={Cynthia Dwork and Guy N. Rothblum},
      year={2016},
      eprint={1603.01887},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
      url={https://arxiv.org/abs/1603.01887}, 
}
@misc{DP05,
      title={Local Differential Privacy and Its Applications: A Comprehensive Survey}, 
      author={Mengmeng Yang and Lingjuan Lyu and Jun Zhao and Tianqing Zhu and Kwok-Yan Lam},
      year={2020},
      eprint={2008.03686},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2008.03686}, 
}
@inproceedings{DP06,
      title={When Machine Unlearning Jeopardizes Privacy},
      url={http://dx.doi.org/10.1145/3460120.3484756},
      DOI={10.1145/3460120.3484756},
      booktitle={Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security},
      publisher={ACM},
      author={Chen, Min and Zhang, Zhikun and Wang, Tianhao and Backes, Michael and Humbert, Mathias and Zhang, Yang},
      year={2021},
      month=nov, pages={896-911},
      collection={CCS '21}
}
@article{DP07,
      author={Wang, Fei and Li, Baochun and Li, Bo},
      journal={IEEE Network}, 
      title={Federated Unlearning and Its Privacy Threats}, 
      year={2024},
      volume={38},
      number={2},
      pages={294-300},
      keywords={Data models;Servers;Federated learning;Training;Biological system modeling;Approximation algorithms;Data privacy;Privacy},
      doi={10.1109/MNET.004.2300056}
}